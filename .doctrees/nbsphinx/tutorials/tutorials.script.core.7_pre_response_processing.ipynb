{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697d8198",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Core: 7. Pre-response processing\n",
    "\n",
    "This tutorial shows pre-response processing feature.\n",
    "\n",
    "Here, [PRE_RESPONSE_PROCESSING](../apiref/chatsky.script.core.keywords.rst#chatsky.script.core.keywords.Keywords.PRE_RESPONSE_PROCESSING)\n",
    "is demonstrated which can be used for\n",
    "additional context processing before response handlers.\n",
    "\n",
    "There are also some other [Keywords](../apiref/chatsky.script.core.keywords.rst#chatsky.script.core.keywords.Keywords)\n",
    "worth attention used in this tutorial.\n",
    "\n",
    "First of all, let's do all the necessary imports from Chatsky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0993727e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T10:58:13.408208Z",
     "iopub.status.busy": "2024-07-05T10:58:13.407957Z",
     "iopub.status.idle": "2024-07-05T10:58:14.724128Z",
     "shell.execute_reply": "2024-07-05T10:58:14.722983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installing dependencies\n",
    "%pip install -q chatsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bdc533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T10:58:14.728583Z",
     "iopub.status.busy": "2024-07-05T10:58:14.728264Z",
     "iopub.status.idle": "2024-07-05T10:58:15.686614Z",
     "shell.execute_reply": "2024-07-05T10:58:15.685741Z"
    }
   },
   "outputs": [],
   "source": [
    "from chatsky.script import (\n",
    "    GLOBAL,\n",
    "    LOCAL,\n",
    "    RESPONSE,\n",
    "    TRANSITIONS,\n",
    "    PRE_RESPONSE_PROCESSING,\n",
    "    Context,\n",
    "    Message,\n",
    ")\n",
    "import chatsky.script.labels as lbl\n",
    "import chatsky.script.conditions as cnd\n",
    "\n",
    "from chatsky.pipeline import Pipeline\n",
    "from chatsky.utils.testing.common import (\n",
    "    check_happy_path,\n",
    "    is_interactive_mode,\n",
    "    run_interactive_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a742dee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T10:58:15.691552Z",
     "iopub.status.busy": "2024-07-05T10:58:15.690764Z",
     "iopub.status.idle": "2024-07-05T10:58:15.695588Z",
     "shell.execute_reply": "2024-07-05T10:58:15.694975Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_prefix(prefix):\n",
    "    def add_prefix_processing(ctx: Context, _: Pipeline):\n",
    "        processed_node = ctx.current_node\n",
    "        processed_node.response = Message(\n",
    "            text=f\"{prefix}: {processed_node.response.text}\"\n",
    "        )\n",
    "\n",
    "    return add_prefix_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a3547",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "`PRE_RESPONSE_PROCESSING` is a keyword that\n",
    "can be used in `GLOBAL`, `LOCAL` or nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff316982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T10:58:15.698589Z",
     "iopub.status.busy": "2024-07-05T10:58:15.698316Z",
     "iopub.status.idle": "2024-07-05T10:58:15.706847Z",
     "shell.execute_reply": "2024-07-05T10:58:15.706171Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "toy_script = {\n",
    "    \"root\": {\n",
    "        \"start\": {\n",
    "            RESPONSE: Message(),\n",
    "            TRANSITIONS: {(\"flow\", \"step_0\"): cnd.true()},\n",
    "        },\n",
    "        \"fallback\": {RESPONSE: Message(\"the end\")},\n",
    "    },\n",
    "    GLOBAL: {\n",
    "        PRE_RESPONSE_PROCESSING: {\n",
    "            \"proc_name_1\": add_prefix(\"l1_global\"),\n",
    "            \"proc_name_2\": add_prefix(\"l2_global\"),\n",
    "        }\n",
    "    },\n",
    "    \"flow\": {\n",
    "        LOCAL: {\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_2\": add_prefix(\"l2_local\"),\n",
    "                \"proc_name_3\": add_prefix(\"l3_local\"),\n",
    "            }\n",
    "        },\n",
    "        \"step_0\": {\n",
    "            RESPONSE: Message(\"first\"),\n",
    "            TRANSITIONS: {lbl.forward(): cnd.true()},\n",
    "        },\n",
    "        \"step_1\": {\n",
    "            PRE_RESPONSE_PROCESSING: {\"proc_name_1\": add_prefix(\"l1_step_1\")},\n",
    "            RESPONSE: Message(\"second\"),\n",
    "            TRANSITIONS: {lbl.forward(): cnd.true()},\n",
    "        },\n",
    "        \"step_2\": {\n",
    "            PRE_RESPONSE_PROCESSING: {\"proc_name_2\": add_prefix(\"l2_step_2\")},\n",
    "            RESPONSE: Message(\"third\"),\n",
    "            TRANSITIONS: {lbl.forward(): cnd.true()},\n",
    "        },\n",
    "        \"step_3\": {\n",
    "            PRE_RESPONSE_PROCESSING: {\"proc_name_3\": add_prefix(\"l3_step_3\")},\n",
    "            RESPONSE: Message(\"fourth\"),\n",
    "            TRANSITIONS: {lbl.forward(): cnd.true()},\n",
    "        },\n",
    "        \"step_4\": {\n",
    "            PRE_RESPONSE_PROCESSING: {\"proc_name_4\": add_prefix(\"l4_step_4\")},\n",
    "            RESPONSE: Message(\"fifth\"),\n",
    "            TRANSITIONS: {\"step_0\": cnd.true()},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# testing\n",
    "happy_path = (\n",
    "    (Message(), \"l3_local: l2_local: l1_global: first\"),\n",
    "    (Message(), \"l3_local: l2_local: l1_step_1: second\"),\n",
    "    (Message(), \"l3_local: l2_step_2: l1_global: third\"),\n",
    "    (Message(), \"l3_step_3: l2_local: l1_global: fourth\"),\n",
    "    (Message(), \"l4_step_4: l3_local: l2_local: l1_global: fifth\"),\n",
    "    (Message(), \"l3_local: l2_local: l1_global: first\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b9c60a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T10:58:15.709812Z",
     "iopub.status.busy": "2024-07-05T10:58:15.709171Z",
     "iopub.status.idle": "2024-07-05T10:58:15.735611Z",
     "shell.execute_reply": "2024-07-05T10:58:15.734639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(user) >>> \n",
      " (bot) <<< text='l3_local: l2_local: l1_global: first'\n",
      "(user) >>> \n",
      " (bot) <<< text='l3_local: l2_local: l1_step_1: second'\n",
      "(user) >>> \n",
      " (bot) <<< text='l3_local: l2_step_2: l1_global: third'\n",
      "(user) >>> \n",
      " (bot) <<< text='l3_step_3: l2_local: l1_global: fourth'\n",
      "(user) >>> \n",
      " (bot) <<< text='l4_step_4: l3_local: l2_local: l1_global: fifth'\n",
      "(user) >>> \n",
      " (bot) <<< text='l3_local: l2_local: l1_global: first'\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline.from_script(\n",
    "    toy_script,\n",
    "    start_label=(\"root\", \"start\"),\n",
    "    fallback_label=(\"root\", \"fallback\"),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_happy_path(pipeline, happy_path)\n",
    "    if is_interactive_mode():\n",
    "        run_interactive_mode(pipeline)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
